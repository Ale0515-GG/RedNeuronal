import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import classification_report
from scipy.sparse import hstack

# Paso 1: Cargar datos
print("Cargando datos...")
df = pd.read_csv("comidas.csv", encoding="latin1")

# Paso 2: Codificar variables categ√≥ricas
le_tipo = LabelEncoder()
df['tipo_preparacion'] = le_tipo.fit_transform(df['tipo_preparacion'])

le_etiqueta = LabelEncoder()
df['etiqueta_encoded'] = le_etiqueta.fit_transform(df['etiqueta'])
etiqueta_clases = le_etiqueta.classes_

print("Clases encontradas:", etiqueta_clases)
print("Cantidad de clases:", len(etiqueta_clases))
print("\nDistribuci√≥n de clases:")
print(df['etiqueta'].value_counts(normalize=True))

# Paso 3: Preparar variables
X_num = df[["calorias", "proteinas", "grasas", "carbohidratos", "tiempo_min", "tipo_preparacion"]]
y = df["etiqueta_encoded"]

# TF-IDF sobre ingredientes
vectorizer = TfidfVectorizer()
X_ing = vectorizer.fit_transform(df["ingredientes"])

# Concatenar num√©ricos + TF-IDF (sparse matrix)
X_full = hstack([X_num, X_ing])

# Paso 4: Divisi√≥n de datos
X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size=0.2, random_state=42)

# Paso 5: Escalado solo para variables num√©ricas
scaler = StandardScaler(with_mean=False)  # with_mean=False porque estamos usando sparse matrices
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Paso 6: Modelo
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.3),
    Dense(len(etiqueta_clases), activation='softmax')
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

print("\nEntrenando modelo de etiquetas nutricionales...")
history = model.fit(X_train.toarray(), y_train, epochs=10, batch_size=16, validation_split=0.2)

# Evaluaci√≥n
loss, acc = model.evaluate(X_test.toarray(), y_test)
print(f"\n‚úÖ Precisi√≥n del modelo en test: {acc*100:.2f}%")

# Reporte de clasificaci√≥n
from sklearn.metrics import classification_report
y_pred = np.argmax(model.predict(X_test.toarray()), axis=1)
print("\nüìä Reporte de clasificaci√≥n:")
print(classification_report(y_test, y_pred, target_names=etiqueta_clases))

# Gr√°fico
plt.figure(figsize=(10,6))
plt.plot(history.history['accuracy'], label='Entrenamiento')
plt.plot(history.history['val_accuracy'], label='Validaci√≥n')
plt.axhline(y=acc, color='r', linestyle='--', label=f'Precisi√≥n Test: {acc*100:.2f}%')
plt.title('Precisi√≥n del modelo de etiquetas nutricionales')
plt.xlabel('√âpocas')
plt.ylabel('Precisi√≥n')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Entrada manual
print("\nüì• Ingresa los datos de tu receta para predecir su etiqueta nutricional:")

try:
    calorias = float(input("Calor√≠as: "))
    proteinas = float(input("Prote√≠nas: "))
    grasas = float(input("Grasas: "))
    carbohidratos = float(input("Carbohidratos: "))
    tiempo_min = float(input("Tiempo de preparaci√≥n (minutos): "))
    tipo_txt = input("Tipo de preparaci√≥n (r√°pido/elaborado): ").strip().lower()
    ingredientes_txt = input("Lista de ingredientes (separados por coma): ")

    if tipo_txt not in le_tipo.classes_:
        raise ValueError("Tipo inv√°lido. Usa 'r√°pido' o 'elaborado'.")

    tipo_encoded = le_tipo.transform([tipo_txt])[0]

    # Datos num√©ricos
    datos_numericos = np.array([[calorias, proteinas, grasas, carbohidratos, tiempo_min, tipo_encoded]])

    # Procesar ingredientes
    datos_ingredientes = vectorizer.transform([ingredientes_txt])

    # Concatenar
    entrada_completa = hstack([datos_numericos, datos_ingredientes])
    entrada_completa = scaler.transform(entrada_completa)

    # Predicci√≥n
    pred_prob = model.predict(entrada_completa.toarray())
    etiqueta_index = np.argmax(pred_prob)
    etiqueta_nombre = etiqueta_clases[etiqueta_index]
    prob_etiqueta = pred_prob[0][etiqueta_index]

    # Clasificaci√≥n saludable o no
    etiqueta_saludable_map = {et: (et != 'no saludable') for et in etiqueta_clases}
    es_saludable = etiqueta_saludable_map[etiqueta_nombre]
    texto_saludable = "‚úÖ Saludable" if es_saludable else "‚ùå No saludable"

    print("\nüîç Resultado de la predicci√≥n:")
    print(f"üè∑Ô∏è Etiqueta nutricional predicha: {etiqueta_nombre} (confianza: {prob_etiqueta*100:.2f}%)")
    print(f"üß† Clasificaci√≥n general: {texto_saludable}")

except Exception as e:
    print(f"‚ùå Error al ingresar datos: {e}")
